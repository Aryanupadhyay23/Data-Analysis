{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+CFeXIV0wo1vT0CUc/Lhh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUdcEkba6vhp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n",
        "webpage = requests.get('https://www.ambitionbox.com/list-of-companies?page=1',headers=headers).text"
      ],
      "metadata": {
        "id": "W3ZkX2aS6zXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(webpage,'lxml')"
      ],
      "metadata": {
        "id": "zps1aWrM67FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "company = soup.find_all('div',class_='company-content-wrapper')"
      ],
      "metadata": {
        "id": "xQoEVRfRCWaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(company)"
      ],
      "metadata": {
        "id": "BSZ2sGjfCh9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name=[]\n",
        "rating=[]\n",
        "reviews=[]\n",
        "ctype=[]\n",
        "hq=[]\n",
        "old=[]\n",
        "employees=[]\n",
        "\n",
        "for i in company:\n",
        "\n",
        "  name.append(i.find('h2').text.strip())\n",
        "  rating.append(i.find('p',class_='rating').text.strip())\n",
        "  reviews.append(i.find('a',class_='review-count').text.strip())\n",
        "  ctype.append(i.find('p',class_='infoEntity').text.strip())\n",
        "  hq.append(i.find('p',class_='infoEntity').text.strip())\n",
        "  old.append(i.find('p',class_='infoEntity').text.strip())\n",
        "  employees.append(i.find('p',class_='infoEntity').text.strip())\n",
        "\n",
        "d={'name':name,'rating':rating,'reviews':reviews,'type':ctype,'hq':hq,'old':old,'employees':employees}\n",
        "\n",
        "df=pd.DataFrame(d)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "69rZZoszCp7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = pd.DataFrame\n",
        "\n",
        "for j in range(1,11):\n",
        "\n",
        "  url='https://www.ambitionbox.com/list-of-companies?page={}.format(j)'\n",
        "\n",
        "\n",
        "  headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n",
        "  webpage = requests.get(url,headers=headers).text\n",
        "\n",
        "  soup=BeautifulSoup(webpage,'lxml')\n",
        "\n",
        "  company=soup.find_all('div',class_='company-content-wrapper')\n",
        "\n",
        "  name=[]\n",
        "  rating=[]\n",
        "  reviews=[]\n",
        "  ctype=[]\n",
        "  hq=[]\n",
        "  old=[]\n",
        "  employees=[]\n",
        "\n",
        "  for i in company:\n",
        "\n",
        "    name.append(i.find('h2').text.strip())\n",
        "    rating.append(i.find('p',class_='rating').text.strip())\n",
        "    reviews.append(i.find('a',class_='review-count').text.strip())\n",
        "    ctype.append(i.find('p',class_='infoEntity').text.strip())\n",
        "    hq.append(i.find('p',class_='infoEntity').text.strip())\n",
        "    old.append(i.find('p',class_='infoEntity').text.strip())\n",
        "    employees.append(i.find('p',class_='infoEntity').text.strip())\n",
        "\n",
        "  d={'name':name,'rating':rating,'reviews':reviews,'type':ctype,'hq':hq,'old':old,'employees':employees}\n",
        "\n",
        "  df=pd.DataFrame(d)\n",
        "\n",
        "  final=final.append(df,ignore_index=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "elGxvnw7Hvup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews"
      ],
      "metadata": {
        "id": "g7nP6wbwEVMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating"
      ],
      "metadata": {
        "id": "tjVfssPZEWRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "company[0].find_all('p',class_='infoEntity')[0].text.strip()"
      ],
      "metadata": {
        "id": "5QY7PIqeEw6p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}